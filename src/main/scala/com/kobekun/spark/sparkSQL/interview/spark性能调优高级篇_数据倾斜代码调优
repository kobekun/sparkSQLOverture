

数据倾斜发生的现象：

    1、绝大多数task执行得都非常快，但个别task执行极慢。比如，总共有1000个task，
    997个task都在1分钟之内执行完了，但是剩余两三个task却要一两个小时。这种情
    况很常见。
    2、原本能够正常执行的Spark作业，某天突然报出OOM（内存溢出）异常，观察异常
    栈，是我们写的业务代码造成的。这种情况比较少见。

数据倾斜发生的原理：

    进行shuffle的时候，必须将各节点上的key拉取到一个节点的task上进行聚合或join操作。
    如果某个key对应的数据量特别大的时候，就会发生数据倾斜。比如，大部分key对应10条数据，但是
    个别key对应100万条数据，那么大部分task可能就会分到10条数据，然后1s就运行完，但是个别task
    分配到100万的数据，需要1-2个小时才能运行完。spark作业的运行进度是由运行时间最长的那个
    task决定

如何定位导致数据倾斜的代码

    数据倾斜只会发生在shuffle过程中，触发shuffle操作的算子：distinct、groupByKey、reduceByKey
    aggregateByKey、join、cogroup、repartition等。出现数据倾斜，可能就是这些算子中某个导致

    1、某个task特别慢的情况
        如果是yarn-client模式提交，那么本地可以直接看到log，在日志中可以看到运行到第几个stage
        如果是yarn-cluster模式提交，可以通过spark webUI来看当前运行到第几个stage
        无论是yarn-client还是yarn-cluster模式，都可以深入地看下当前这个stage各个task分配
        的数据量。从而确定是不是task分配的数据量不均匀导致的数据倾斜

        知道数据倾斜发生在哪个stage之后，接着需要根据stage划分原理，推算出发生数据倾斜的那个stage
        对应的代码，这部分代码肯定有shuffle算子。推算方法：
        只要看到看到代码中出现了shuffle类算子或者sparkSQL的SQL语句中出现了导致shuffle的语句
        （比如group by），就可以断定以此为界前后出现两个stage

       单词计数来举例，如何用最简单的方法大致推算出一个stage对应的代码。如下示例，在整个代码中，只有
       一个reduceByKey是会发生shuffle的算子，因此就可以认为，以这个算子为界限，会划分出前后两个
       stage。 * stage0，主要是执行从textFile到map操作，以及执行shuffle write操作。shuffle write
       操作，我们可以简单理解为对pairs RDD中的数据进行分区操作，每个task处理的数据中，相同的key会写
       入同一个磁盘文件内。 * stage1，主要是执行从reduceByKey到collect操作，stage1的各个task一开始
       运行，就会首先执行shuffle read操作。执行shuffle read操作的task，会从stage0的各个task所在节
       点拉取属于自己处理的那些key，然后对同一个key进行全局性的聚合或join等操作，在这里就是对key的
       value值进行累加。stage1在执行完reduceByKey算子之后，就计算出了最终的wordCounts RDD，然后会
       执行collect算子，将所有数据拉取到Driver上，供我们遍历和打印输出。

       val conf = new SparkConf()
       val sc = new SparkContext(conf)

       val lines = sc.textFile("hdfs://...")
       val words = lines.flatMap(_.split(" "))
       val pairs = words.map((_, 1))
       val wordCounts = pairs.reduceByKey(_ + _)

       wordCounts.collect().foreach(println(_))


    2、某个task莫名其妙内存溢出的情况
        直接看yarn-client模式下本地log的异常栈，或者是通过YARN查看yarn-cluster模式下的log中的异常栈。
        一般来说，通过异常栈信息就可以定位到你的代码中哪一行发生了内存溢出。然后在那行代码附近找找，一般
        也会有shuffle类算子，此时很可能就是这个算子导致了数据倾斜。

查看导致数据倾斜的key的数据分布情况

    分析执行了shuffle操作并导致数据倾斜的hive表，查看下key的分布情况

    查看key的分布的方式：1、如果是sparkSQL中group by 或者join语句导致的数据倾斜，就查询下该表key的分布
    情况 2、如果sparkrdd执行的shuffle算子导致的数据倾斜，那么可以在代码中加入各个可以出现的次数，collect
    或者take到客户端打印一下，可以看到key的分布情况

    可以先对pairs采样10%的样本数据，然后使用countByKey算子统计出每个key出现的次数，最后在客户端遍历和打印
    样本数据中各个key的出现次数。

    val sampledPairs = pairs.sample(false, 0.1)
    val sampledWordCounts = sampledPairs.countByKey()
    sampledWordCounts.foreach(println(_))

数据倾斜的解决方案：

    1、使用hive etl预处理数据

        适用场景：导致数据倾斜的是hive表。hive表的数据分布不均匀，而且频繁使用spark对hive表执行某个分析
        操作

        实现思路：评估是否通过hive进行数据预处理(即通过hive ETL预先对数据按照key进行聚合，或者预先和
        其他表进行join)，然后spark作业中的数据源就不是原来的hive表，而是预处理后的hive表。由于已经预先
        聚合或者join过，所以spark作业后面不需要进行shuffle类算子的操作

        实现原理：治标不治本。把数据倾斜的可能性推到了hive ETL。hive ETL时会用到group by 或join，还是
        可能出现数据倾斜

        优点：操作简单，效果好，spark作业完全规避掉数据倾斜。性能大大提升
        缺点：指治标不治本。hive ETL还是可能会发生数据倾斜

        实践经验：在java和spark结合的项目中，java代码会频繁的调用spark作业，而且对spark作业的性能要求较高
        将数据倾斜提前提到上游的hive ETL上，每天执行一次，在凌晨业务不是很繁忙的时候执行，可能会花几个小时
        只有这一次比较慢，而之后java调用spark作业的时候，执行速度都比较快

    2、过滤少数导致数据倾斜的key

        适用场景：如果发生数据倾斜的key只有少数几个，对计算本身并不大的话，就很适合此种场景。比如99%的key
        只有几条数据，而只有一个key对应100万条数据，从而导致数据倾斜。

        实现思路：sparkSQL中可以使用where子句过滤掉这些key或者sparkcore中rdd执行filter算子过滤掉这些
        key。如果每次作业动态判断哪个key最多，可以使用sample算子对rdd取样，计算出每个key的数量，过滤掉
        key最多的

        实现原理：过滤掉发生数据倾斜的key，key不参与计算，自然不可能产生数据倾斜
        优点：简单，效果好
        缺点：适用场景不多，导致数据倾斜的key还是比较多的

        实践经验：突然某天，spark作业运行oom，追查发现，是hive表中某个key在那天数据异常，导致数据量暴增。
        因此，执行作业前先采样，取出数据量最大的几个key，直接在程序中过滤掉几个key。

    3、提高shuffle操作的并行度

        适用场景：如果需要设参来解决数据倾斜，可以考虑这种方案

        实现思路：在对rdd执行shuffle算子时，给算子传入一个参数，比如reduceByKey(1000)，该参数就设置了这个
        shuffle算子执行时shuffle read task的数量。   对于sparkSQL中的shuffle算子，比如group by、join等
        需要设置一个参数，即spark.sql.shuffle.partitions,该参数代表了shuffle read task的数量。默认是200，
        对于很多场景来说都有点过小

        实现原理：增加shuffle read task的数量，可以把原本分配给一个task的多个key分配给多个task上，从而每个
        task处理比原来更少的数据。

        优点：可以有效缓解和减轻数据倾斜的影响
        缺点：只是缓解，没有根除。从实践来看，效果有限
        实践经验：该方案无法彻底解决数据倾斜，如果出现一些极端情况，比如某个key对应的数据量有100万，无论task数量
        增加到多少，对应100万数据的key肯定还是会分配到一个task中取处理，因此还是会发生数据倾斜。所以此种方案
        只是缓解，或者和其他方案结合起来使用

     4、两阶段聚合(局部聚合或全局聚合)

        适用场景：对rdd执行reduceByKey操作或者在sparkSQL中使用group by进行聚合时，比较适用
        实现思路：核心思路是两阶段聚合。第一次是局部聚合，先给每个key都打上一个随机数，比如10以内的随机数，
        此时原先一样的key就变成不一样了，比如(hello, 1) (hello, 1) (hello, 1) (hello, 1)，就会变成
        (1_hello, 1) (1_hello, 1) (2_hello, 1) (2_hello, 1)。接着对打上随机数后的数据，执行reduceByKey
        等聚合操作，进行局部聚合，那么局部聚合结果，就会变成了(1_hello, 2) (2_hello, 2)。然后将各个key的前
        缀给去掉，就会变成(hello,2)(hello,2)，再次进行全局聚合操作，就可以得到最终结果了，比如(hello, 4)。

        实现原理：将原本相同的key通过附加随机数的方式，变成多个不同的key，就可以让原来被一个task处理的数据
        分散到多个task上去做局部聚合，从而解决了单个task处理数据量过多的问题。接着去掉随机数前缀，再次进行
        全局聚合，可以得到最终的结果。具体原理见 局部全局聚合原理图.png

        优点：对于聚合类的shuffle操作，效果很不错。通常可以解决掉数据倾斜。或者至少可以
        大幅度缓解数据倾斜，将spark作业性能提升数倍
        缺点：仅仅适用聚合类的shuffle操作。如果是join类的shuffle操作，还得其他解决方案


     5、将reduce join转为map join

        适用场景：在对rdd使用join类操作，或者在sparkSQL中使用join语句时，而join操作中一个rdd
        或者表的数据量比较小(几百M或者一两G)
        实现思路：不使用join算子进行连接操作。将较小rdd中的数据通过collect算子将数据拉取到Driver
        端的内存中，对其创建broadcast变量。对另一个rdd执行map操作，从broadcast中获取较小rdd的数据与
        当前rdd的每一条数据按照key进行对比，如果key相同，就将两个数据连接起来

        实现原理：普通join走shuffle。如果一个RDD是比较小的，则可以采用广播小RDD全量数据+map算子
        来实现与join同样的效果，也就是map join，就不会发生数据倾斜。

        优点：对join操作的数据倾斜，效果非常好，不会发生数据倾斜
        缺点：适用场景较少，因为这个方案只适用于一个大表和一个小表的情况。毕竟我们需要将小表进行广
        播，此时会比较消耗内存资源，driver和每个Executor内存中都会驻留一份小RDD的全量数据。

     6、采用倾斜key并分拆join操作

        适用场景：两个RDD/hive表join的时候，如果数据量比较大，可以看下两个RDD/hive的key
        分布情况。如果数据出现倾斜，是因为其中一个RDD/hive表中的几个key数据量大，而另一个
        RDD/hive表的key分布均匀，采用此方案比较合适

        实现思路：1、对包含少数几个数据量大的key的rdd或hive表进行sample取样，统计每个key的
        数量，计算出数据量最大的那几个key。2、将这几个key对应的数据从原来的rdd中拆分出来，
        形成单独的rdd，并给每个key都打上n以内的随机数作为前缀，而不会导致倾斜的大部分key形成
        另外一个rdd。3、。。

        实现原理：对于join导致的数据倾斜，如果只是其中几个key导致倾斜，key将少数几个key分拆成
        独立rdd，并附加随机前缀打散成n份进行join，此时几个key对应的数据就不会集中在少数几个task上
        而是分散到多个task进行join

        优点：对应join导致的数据倾斜，如只是某几个key导致倾斜，采用该方法将key打散进行join。
        而且只需要针对少数倾斜key对应的数据进行扩容n倍，不需要对全量数据扩容。避免占用过多内存
        缺点：如果导致倾斜的key较多，比如成千上万，此种方法显然不合适。

     7、使用随机前缀和扩容rdd进行join

        使用场景：大量key导致的数据倾斜，用此方案

        实现思路：和6类似，看rdd或hive表的数据分布情况，找到造成数据倾斜的rdd或hive表，
        比如有多个key都对应超过1万条数据，将该rdd的每条数据都打上一个n以内的随机前缀，
        同时对另外一个rdd进行扩容，将每条数据都扩容成n条数据，扩容出来的每条数据都依次打
        上一个0-n的前缀。最后将两个处理后的rdd进行join

        实现原理：将原先一样的key通过附加随机前缀变成不一样的key，然后就可以将这些处理后
        的“不同key”分散到多个task中去处理，而不是让一个task处理大量的相同key。该方案与
        “解决方案六”的不同之处就在于，上一种方案是尽量只对少数倾斜key对应的数据进行特殊
        处理，由于处理过程需要扩容RDD，因此上一种方案扩容RDD后对内存的占用并不大；而这
        一种方案是针对有大量倾斜key的情况，没法将部分key拆分出来进行单独处理，因此只能
        对整个RDD进行数据扩容，对内存资源要求很高。

        优点：对join导致倾斜的基本都可以处理，效果比较显著
        缺点：该方案更多的是缓解数据倾斜，而不是彻底避免，而且对整个rdd进行扩容，对内存资源
        要求很高

        实践经验：有个需求，join导致数据倾斜，花费一个小时左右跑完作业，使用该方案优化后，
        执行时间缩短到10分钟左右，性能提升6倍

     8、多种方案组合使用








