


SortShuffleManager相较于HashShuffleManager来说，有了一定的改进。主要就在于，每个Task在进
行shuffle操作时，虽然也会产生较多的临时磁盘文件，但是最后会将所有的临时文件合并（merge）成一
个磁盘文件，因此每个Task就只有一个磁盘文件。在下一个stage的shuffle read task拉取自己的数据
时，只要根据索引读取每个磁盘文件中的部分数据即可。

SortShuffleManager运行原理

SortShuffleManager的运行机制主要分成两种，一种是普通运行机制，另一种是bypass运行机制。
当shuffle read task的数量小于等于spark.shuffle.sort.bypassMergeThreshold参数的值时
（默认为200），就会启用bypass机制。

在该模式下，数据会先写入一个内存数据结构中，此时根据不同的shuffle算子，可能选用不同的数据
结构。如果是reduceByKey这种聚合类的shuffle算子，那么会选用Map数据结构，一边通过Map进行聚合
，一边写入内存；如果是join这种普通的shuffle算子，那么会选用Array数据结构，直接写入内存。接着
，每写一条数据进入内存数据结构之后，就会判断一下，是否达到了某个临界阈值。如果达到临界阈值的话，
那么就会尝试将内存数据结构中的数据溢写到磁盘，然后清空内存数据结构。

在溢写到磁盘文件之前，会先根据key对内存数据结构中已有的数据进行排序。排序过后，会分批将数据
写入磁盘文件。默认的batch数量是10000条，也就是说，排序好的数据，会以每批1万条数据的形式分批
写入磁盘文件。写入磁盘文件是通过Java的BufferedOutputStream实现的。BufferedOutputStream是
Java的缓冲输出流，首先会将数据缓冲在内存中，当内存缓冲满溢之后再一次写入磁盘文件中，这样可以
减少磁盘IO次数，提升性能。

一个task将所有数据写入内存的过程中，会发生多次磁盘溢写操作，也就会产生多个临时文件。
最后会将之前所有的临时磁盘文件都进行合并，这就是merge过程，此时会将之前所有临时磁盘文件中的数
据读取出来，然后依次写入最终的磁盘文件之中。此外，由于一个task就只对应一个磁盘文件，也就意味着
该task为下游stage的task准备的数据都在这一个文件中，因此还会单独写一份索引文件，其中标识了下
游各个task的数据在文件中的start offset与end offset。

SortShuffleManager由于有一个磁盘文件merge的过程，因此大大减少了文件数量。

bypass运行机制

触发条件：1、shuffle map task数量小于spark.shuffle.sort.bypassMergeThreshold参数的
值。2、不是聚合类的shuffle算子(比如reduceByKey)

按照key的hash将磁盘先写入内存缓存，缓存满之后再一次性写入磁盘。最后合并成一个磁盘文件，并
创建单独的索引文件。

少量的最终磁盘文件，也让该机制相对未经优化的HashShuffleManager来说，shuffle read
的性能会更好。

而该机制与普通SortShuffleManager运行机制的不同在于：第一，磁盘写机制不同；第二，不会
进行排序。 不进行排序操作，节省了性能开销。


shuffle参数调优：
    1、spark.shuffle.file.buffer
        默认值：32k
        参数说明：该参数用于设置shuffle write task的BufferedOutputStream的buffer
        缓冲大小。将数据写入磁盘之前，会先写入buffer中，待缓冲写满之后，才会溢写到磁盘
        调优建议：如果作业可用的内存资源充足，可将值调为64k，以减少磁盘io次数
    2、spark.reducer.maxSizeInFlight
        默认值：48m
        参数说明：该参数用于设置shuffle read task的buffer缓冲大小。此buffer决定了每次拉取
        多少数据
        调优建议：如果资源充足，可用适当的增加这个参数的大小(96m)，从而减少拉取数据的次数，
        也就可以减少网络传输，进而提高性能
    3、spark.shuffle.io.maxRetries
        默认值：3
        参数说明：shuffle read task从write task所在节点拉取属于自己的数据时，如果因为网络
        异常导致拉取失败，会自动重试。该参数代表了重试的最大次数。指定次数没有拉取成功。作业
        可能会失败
        调优建议：对于特别耗时的shuffle操作的作业，建议增加重试最大次数，比如60次，以避免JVM的
        full GC或者网络不稳定导致的数据拉取失败
        实践中发现，对于针对超大数据量（数十亿~上百亿）的shuffle过程，调节该参数可以大幅度提升稳定性。
    4、spark.shuffle.io.retryWait
        默认值：5s
        参数说明：每次重试拉取数据的等待间隔。
        调优建议：建议加大间隔，以增加shuffle操作的稳定性

    5、spark.shuffle.memoryFraction
        默认值：0.2
        参数说明：该参数代表了Executor内存中，分配给shuffle read task进行聚合操作的内存比例，默认是20%。
        调优建议：如果内存充足，而且很少使用持久化操作，建议调高此比例，给shuffle read聚合操作
        更多内存，以避免由于内存不足导致聚合过程中频繁读写磁盘

    6、spark.shuffle.manager
        默认值：sort
        参数说明：该参数用于设置ShuffleManager的类型。Spark 1.5以后，有三个可选项：hash、sort和tungsten-sort。
        HashShuffleManager是Spark 1.2以前的默认选项，但是Spark 1.2以及之后的版本默认都是SortShuffleManager了。
        调优建议：由于SortShuffleManager默认会对数据进行排序，因此如果你的业务逻辑中需要
        该排序机制的话，则使用默认的SortShuffleManager就可以；而如果你的业务逻辑不需要对
        数据进行排序，那么建议参考后面的几个参数调优，通过bypass机制或优化的
        HashShuffleManager来避免排序操作，同时提供较好的磁盘读写性能。
        这里要注意的是，tungsten-sort要慎用，因为之前发现了一些相应的bug。

    7、spark.shuffle.sort.bypassMergeThreshold

        默认值：200
        参数说明：当ShuffleManager为SortShuffleManager时，如果shuffle read task的数量
        小于这个阈值（默认是200），则shuffle write过程中不会进行排序操作，而是直接按照未
        经优化的HashShuffleManager的方式去写数据，但是最后会将每个task产生的所有临时磁
        盘文件都合并成一个文件，并会创建单独的索引文件。
        调优建议：当你使用SortShuffleManager时，如果的确不需要排序操作，那么建议将这个参
        数调大一些，大于shuffle read task的数量。那么此时就会自动启用bypass机制，
        map-side就不会进行排序了，减少了排序的性能开销。但是这种方式下，依然会产生大量的
        磁盘文件，因此shuffle write性能有待提高。

    8、spark.shuffle.consolidateFiles

        默认值：false
        参数说明：如果使用HashShuffleManager，该参数有效。如果设置为true，那么就会开启consolidate机制，会大幅度合
        并shuffle write的输出文件，对于shuffle read task数量特别多的情况下，这种方法可
        以极大地减少磁盘IO开销，提升性能。
        调优建议：如果的确不需要SortShuffleManager的排序机制，那么除了使用bypass机制，
        还可以尝试将spark.shffle.manager参数手动指定为hash，使用HashShuffleManager，
        同时开启consolidate机制。在实践中尝试过，发现其性能比开启了bypass机制的
        SortShuffleManager要高出10%~30%。



