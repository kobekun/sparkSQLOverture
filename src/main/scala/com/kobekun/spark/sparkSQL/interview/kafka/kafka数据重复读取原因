

kafka 数据重复读取原因及解决方案

    出现这个问题，一般都是设置kafkaoffset自动提交的时候发生的。
    原因在于数据处理时间大于max.poll.interval.ms（默认300s），
    导致offset自动提交失败，以致offset没有提交。重新读取数据的时候
    又会读取到kafka之前消费但没有提交offset的数据，从而导致读取到重复数据。



    解决方案：
    1、增大max.poll.interval.ms，默认是300s，不推荐
    2、减小max.poll.records,推荐
    3、使用手动提交offset方法consumer.commitSync()/consumer.commitAsync()，在不确定数据情况下推荐
    4、一个线程消费kafka数据，消费后将数据传给其他线程处理


    原文链接：https://blog.csdn.net/llflilongfei/article/details/81483509















