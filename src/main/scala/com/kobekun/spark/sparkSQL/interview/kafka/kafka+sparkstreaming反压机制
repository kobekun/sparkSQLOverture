
配置sparkstreaming的反压机制，避免
1、首次启动streaming应用，kafka保留了大量未消费历史消息，并且auto.offset.reset=
latest,可以防止第一个batch接收大量消息、处理时间过长和内存溢出
2、防止producer突然生产大量消息，一个batch接收到大量消息，导致batch之间接收的数据倾斜

启用反压也比较简单：sparkConf.set("spark.streaming.backpressure.enabled",
"true")。spark会在作业执行结束后，调用RateController.onBatchCompleted更新
batch的元数据信息：batch处理结束时间、batch处理时间、调度延迟时间、batch接收到
的消息量等.

链接：https://www.jianshu.com/p/c0b724137416










